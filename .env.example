# For OpenAI
# OPENAI_API_KEY=sk-...
# DSPY_LM_PROVIDER=openai
# DSPY_LM_MODEL=gpt-5.1-codex

# For Anthropic
# ANTHROPIC_API_KEY=sk-ant-...
# DSPY_LM_PROVIDER=anthropic
# DSPY_LM_MODEL=claude-4-5-haiku

# For Ollama (local AI)
# DSPY_LM_PROVIDER=ollama
# DSPY_LM_MODEL=qwen3
# OLLAMA_BASE_URL=http://localhost:11434/v1

# For OpenRouter (access multiple models)
# OPENROUTER_API_KEY=sk-or-...
# DSPY_LM_PROVIDER=openrouter
# DSPY_LM_MODEL=x-ai/grok-4.1-fast:free

# Vector Database (Qdrant) & Embeddings
# QDRANT_URL=http://localhost:6333
# EMBEDDING_PROVIDER=openai # or ollama, openrouter
# EMBEDDING_BASE_URL=https://api.openai.com/v1 # Required for OpenRouter/Ollama
# EMBEDDING_API_KEY=sk-... # Defaults to OPENAI_API_KEY if not set
# EMBEDDING_MODEL=text-embedding-3-small

# Matryoshka Embeddings (dimension truncation)
# Only works with compatible models: qwen3-embedding:8b/4b/0.6b, nomic-embed-text
# Dimensions are truncated BEFORE storing in Qdrant
# GRAPHRAG_EMBEDDING_DIM=1024 # GraphRAG entity dimension
# CODEBASE_EMBEDDING_DIM=1024 # Codebase search dimension
# LEARNINGS_EMBEDDING_DIM=2048 # Knowledge base dimension
# GRAPHRAG_INDEXING_MODE=ask # ask | auto | never

# Langfuse (Observability)
# LANGFUSE_PUBLIC_KEY=pk-lf-...
# LANGFUSE_SECRET_KEY=sk-lf-...
# LANGFUSE_HOST=https://cloud.langfuse.com
# LANGFUSE_BASE_URL=https://cloud.langfuse.com

# Logging & UI
# COMPOUNDING_LOG_PATH=compounding.log
# COMPOUNDING_LOG_LEVEL=DEBUG
# COMPOUNDING_QUIET=false

# System & Context
# COMPOUNDING_ENV=.env
# CONTEXT_WINDOW_LIMIT=128000
# CONTEXT_OUTPUT_RESERVE=4096
# DSPY_MAX_TOKENS=16384
